#!/usr/bin/env python3
"""
Roll up signals/*.json into docs/digests/YYYY-WW.md (ISO week).
- Computes counts, total weight, top signals, tag histogram
- Includes records whose timestamp is within the target ISO week
- If timestamp missing, uses file mtime

Usage:
  python scripts/generate_weekly_digest.py --week 2025-39 --write
"""
import argparse
import json
import os
import sys
from glob import glob
from datetime import datetime, timezone
from collections import Counter


DIGEST_DIR = 'docs/digests'


def iso_year_week(dt):
    """Get ISO year-week string (YYYY-WW) from datetime."""
    iso = dt.isocalendar()  # (year, week, weekday)
    return f"{iso[0]}-{iso[1]:02d}"


def within_week(dt, target):
    """Check if datetime is within target ISO week."""
    return iso_year_week(dt) == target


def coerce_datetime(value, default=None):
    """Convert string to datetime, return default if failed."""
    if not value:
        return default
    
    try:
        # Try dateutil parser for flexible parsing
        from dateutil import parser as date_parser
        return date_parser.parse(value)
    except ImportError:
        # Fallback to basic ISO format parsing
        try:
            return datetime.fromisoformat(value.replace('Z', '+00:00'))
        except Exception:
            return default
    except Exception:
        return default


def main():
    """Generate weekly digest from signals."""
    parser = argparse.ArgumentParser(description="Generate weekly signals digest")
    parser.add_argument('--week', help='YYYY-WW, defaults to current week')
    parser.add_argument('--write', action='store_true', help='Write to file')
    parser.add_argument('--top', type=int, default=10, help='Number of top signals')
    args = parser.parse_args()

    # Determine target week
    now = datetime.now(timezone.utc)
    target_week = args.week or iso_year_week(now)
    
    # Ensure digest directory exists
    os.makedirs(DIGEST_DIR, exist_ok=True)

    # Process signal files
    files = sorted(glob('signals/*.json'))
    items = []
    
    for filepath in files:
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                obj = json.load(f)
        except Exception:
            continue
        
        # Get timestamp (from object or file mtime)
        timestamp = coerce_datetime(obj.get('timestamp'), None)
        if not timestamp:
            mtime = os.path.getmtime(filepath)
            timestamp = datetime.fromtimestamp(mtime, tz=timezone.utc)
        
        # Skip if not in target week
        if not within_week(timestamp, target_week):
            continue
        
        # Extract signal data
        weight = obj.get('weight', 1)
        title = (obj.get('title') or 
                obj.get('summary') or 
                obj.get('id') or 
                os.path.basename(filepath))
        tags = obj.get('tags') or []
        
        items.append({
            'id': obj.get('id', '(no-id)'),
            'title': title,
            'weight': float(weight),
            'tags': tags
        })

    # Calculate metrics
    count = len(items)
    total_weight = sum(item['weight'] for item in items)
    
    # Get top signals by weight
    top_signals = sorted(items, key=lambda x: (-x['weight'], x['title']))[:args.top]
    
    # Tag frequency analysis
    tag_counter = Counter(tag for item in items for tag in (item['tags'] or []))
    top_tags = tag_counter.most_common(12)

    # Build digest content
    content_lines = []
    content_lines.append(f"# Weekly Digest — {target_week}\n")
    content_lines.append("## Metrics\n")
    content_lines.append(f"- Signals this week: **{count}**")
    content_lines.append(f"- Total weight: **{total_weight:.2f}**\n")
    
    if top_signals:
        content_lines.append("## Top Signals\n")
        for i, item in enumerate(top_signals, 1):
            content_lines.append(
                f"{i}. **{item['title']}** — weight `{item['weight']}`  "
                f"_(id: {item['id']})_"
            )
        content_lines.append("")
    
    if top_tags:
        content_lines.append("## Tag Leaderboard\n")
        for tag, count in top_tags:
            content_lines.append(f"- {tag}: {count}")
        content_lines.append("")

    content_lines.append("---")
    content_lines.append("<sub>Generated by VaultMesh Signals • Solve et Coagula</sub>")
    
    # Generate final content
    content = "\n".join(content_lines) + "\n"
    
    # Output or write
    output_path = os.path.join(DIGEST_DIR, f"{target_week}.md")
    
    if args.write:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"✅ Wrote {output_path}")
    else:
        print(content)
    
    return 0


if __name__ == '__main__':
    sys.exit(main())

